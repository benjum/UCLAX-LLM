{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ccb78b-0e65-4a02-858c-e1e5bc0b0fbe",
   "metadata": {},
   "source": [
    "# Text classification approaches on news-like data -- Continued\n",
    "\n",
    "Extending to fine-tuning!  Here we will do simple LLM fine-tuning with DistilBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff60a1-9b29-45bf-832b-f22df53575f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "# For LLM fine-tuning\n",
    "from datasets import Dataset as HFDataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb89cd-ba5a-4833-854f-6960ba8d9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Reproducibility\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090a395-8d1b-4cc0-b5de-888931ce6392",
   "metadata": {},
   "source": [
    "### Load and prepare data\n",
    "\n",
    "* Load a subset of 20 Newsgroups as a stand-in for 'news' articles.\n",
    "* We pick a few categories to make it multi-class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e99df0-54b7-460f-a60c-708f23186074",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"rec.autos\",\n",
    "    \"sci.space\",\n",
    "    \"comp.graphics\",\n",
    "    \"talk.politics.misc\",\n",
    "]\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c57d8-740d-4845-a692-b3501e1aab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    remove=(\"headers\", \"footers\", \"quotes\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd789f91-472a-4fe7-8667-6d27729c9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dataset.data\n",
    "labels = dataset.target\n",
    "target_names = dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda3dd6-3687-4bc2-b168-4ff829d768b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54072e14-411e-428b-91c9-00f0f69e588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[0], ':', target_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497be4d-4b8f-4de5-8321-fb2e96de9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_SEED, \n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3eb401-93e9-48df-a452-d3a2b90ddc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(texts)} documents, {len(target_names)} classes:\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"  {i}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a660c4d-7b42-40b1-a5b7-e68c9b98c0aa",
   "metadata": {},
   "source": [
    "### 4. Simple LLM Fine-Tuning (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49e8eb-24bb-4d9f-89ce-6169465bd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hf_dataset(X_train, X_test, y_train, y_test):\n",
    "    train_dict = {\"text\": X_train, \"label\": y_train}\n",
    "    test_dict = {\"text\": X_test, \"label\": y_test}\n",
    "\n",
    "    train_dataset = HFDataset.from_dict(train_dict)\n",
    "    test_dataset = HFDataset.from_dict(test_dict)\n",
    "\n",
    "    return DatasetDict({\"train\": train_dataset, \"test\": test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745daba-3c79-4929-b4dc-6a4d3bb406de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples, tokenizer, max_length=256):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99721eb5-cbe6-48d1-97f0-c4e47f3b4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, \n",
    "                                                               preds, \n",
    "                                                               average=\"weighted\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67136900-e106-4fd2-b326-388b2f0c477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548eaffa-efe5-45a2-bbe3-cc438f4c6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_datasets = prepare_hf_dataset(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb0e07-a4ae-4c39-a6b5-4d273d65fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077cb56-afd1-4410-9f4a-7a08668b1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokenized_datasets = hf_datasets.map(\n",
    "    lambda example: tokenize_function(example, tokenizer),\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4bdb5-4b2f-4d93-b0c8-80ac3530c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e889c3-e383-4a54-8017-ed1fe980409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b83993-e4a8-461d-af78-8adc66c59e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c1e79-9c79-404a-9bfa-13288bd40f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970e4036-1d11-40bd-964c-4116b5ed6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b5258-8fb7-4567-ad0c-ef06f7778f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][0]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc116b-7d1a-4dd7-9d72-351b021f1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a4fe7-86ae-4a83-83ed-265cbc019804",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07771563-b188-4c6d-a425-e78185668feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854b6ba-33c7-483c-8719-00c66288e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270d7a2-c6a1-4f67-9975-6ee19a2dc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilbert-base-uncased-news\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,  # small here for quick running\n",
    "    learning_rate=5e-5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4abaa8-0105-4645-9493-039521e2323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bfca78-82cb-44d2-96e2-54d92a59cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298e3bb-a364-49b9-8cde-9853974f3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(\"DistilBERT eval metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28184a8-1d9f-41fb-a895-d3648f419080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a small classification report\n",
    "preds_output = trainer.predict(tokenized_datasets[\"test\"])\n",
    "preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "\n",
    "print(\"\\nClassification report (DistilBERT fine-tuned):\")\n",
    "print(classification_report(y_test, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b05956-68a5-4a6e-87b7-10311ffa0c5f",
   "metadata": {},
   "source": [
    "# Freezing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47da3b7-e6a4-4e8c-b3b9-d07156eede47",
   "metadata": {},
   "source": [
    "Following the book, we can check what parameters in our DistilBert model are trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e7b5e-4fc0-4e3b-b2a2-503460eedc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd694e-3836-428c-a076-a9b13eb515b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (name, param) in enumerate(model.named_parameters()):\n",
    "     print(f\"Parameter: {index}{name} ----- {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d7fd19-b380-4f03-b788-94d93cec21d2",
   "metadata": {},
   "source": [
    "Given our small dataset, maybe we shouldn't try and train the entire model.\n",
    "\n",
    "Let's try:\n",
    "1. only training the final classifier parameters\n",
    "2. only training the final transformer block + classifier head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd69df4-280b-4ba3-854d-17754b08f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classifier block starts at index 102\n",
    "# The final transformer block (#5) starts at index 84\n",
    "# We can freeze everything up to those indices to constrain our training\n",
    "\n",
    "model_ix_to_unfreeze = 84\n",
    "\n",
    "for index, (name, param) in enumerate(model.named_parameters()):\n",
    "    param.requires_grad = True\n",
    "    if index < model_ix_to_unfreeze:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600088f-b400-451d-9bb0-91cd43e804bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (name, param) in enumerate(model.named_parameters()):\n",
    "     print(f\"Parameter: {index}{name} ----- {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e61775-9923-4a46-8ea0-6db2dfc51059",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd38901-1d4b-4a7d-9e71-996e1ff5cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a small classification report\n",
    "preds_output = trainer.predict(tokenized_datasets[\"test\"])\n",
    "preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "\n",
    "print(\"\\nClassification report (DistilBERT fine-tuned):\")\n",
    "print(classification_report(y_test, preds, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
